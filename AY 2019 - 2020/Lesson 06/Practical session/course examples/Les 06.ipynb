{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelling of Cognitive Processes\n",
    "## Delta learning \n",
    "---\n",
    "Lesson 06   \n",
    "29/10/2019   \n",
    "Pieter Huycke   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "## Theoretical\n",
    "- Delta learning: quick recap\n",
    "\n",
    "## Practical\n",
    "1. Florence + the machine: a Delta learning tutorial\n",
    "2. Modelling the blocking effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The delta rule\n",
    "\n",
    "In the last theoretical lesson, we considered the mean squared error (MSE) function, which has the following form:\n",
    "\n",
    "$$E = \\frac{1}{n} \\sum_{i=1}^{n} (t_{i} - y_{i})^2$$\n",
    "\n",
    "where $t_{i}$ are the values provided by the supervisor.   \n",
    "Hence, this type of learning belongs to the category of __supervised learning__.   \n",
    "Recall that minimizing this function is straightforward: we have to minimize the difference between the predicted values $y_{i}$ and the 'required' values $t_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The delta rule\n",
    "\n",
    "We apply gradient descent in weight space, expressed mathematically using the following equation:\n",
    "\n",
    "$$\\Delta w_{ij} = - \\beta \\frac{\\partial E}{\\partial w_{ij}}$$\n",
    "\n",
    "Mind that the notation $\\frac{\\partial f(x,y)}{\\partial y}$ refers to the partial derivative of the function $f(x,y)$ with respect to variable $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The delta rule\n",
    "\n",
    "Working out this equation algebraically brings us to the following equation:\n",
    "\n",
    "$$\\Delta w_{ij} = \\beta_{j} (t_{i} - y_{i}) \\frac{\\partial}{\\partial in_{i}} f(in_{i})$$\n",
    "\n",
    "Which can be simplified if we use the linear activation function to:\n",
    "\n",
    "$$\\Delta w_{ij} = \\beta_{j} (t_{i} - y_{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Florence + the machine: a Delta learning tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The unknown artist\n",
    "\n",
    "Imagine you are listening to the radio, and suddenly a song comes up that you really like.   \n",
    "After the song, the radio host mentions the song 'Stand by me' by 'Florence + the machine'.   \n",
    "   \n",
    "You decide to search them online, and you find the following information..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence + the machine\n",
    "\n",
    "- English indie rock band\n",
    "- Formed in London in 2007\n",
    "- Lead singer: Florence Welch ‚¨áÔ∏è\n",
    "\n",
    "![Image of Florence](./florence.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the modelling aproach\n",
    "\n",
    "When you now hear _Stand by me_ again, you will be able to conjure up Florence's picture in your mind.   \n",
    "In MCP terms: you learned an association between two items.   \n",
    "Please note that encountering one item (the song) will result in the second item (the mental picture of Florence you saw online).\n",
    "\n",
    "We have already seen these dynamics in the cat-dog model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: comparison with the pet detector\n",
    "\n",
    "Note that the pet detector also worked with specific features.   \n",
    "\n",
    "![The pet detector](./cat_dog_model.jpg)\n",
    "\n",
    "**What do we expect here?**   \n",
    "```input = np.array([0, 1, 1])```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: comparison with the pet detector\n",
    "\n",
    "**Model input**\n",
    "- Unit 1 is **inactive**: does not bite visitors\n",
    "- Unit 2 is **active**: has 4 legs\n",
    "- Unit 3 is **active**: has a picture on Facebook\n",
    "\n",
    "**Model output**   \n",
    "![Cat](./cat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the modelling aproach\n",
    "\n",
    "Mind what happened:\n",
    "- First, the song was not associated with mental images\n",
    "- After the Google search, we could picture the singer of this song\n",
    "\n",
    "How?   \n",
    "**Learning**\n",
    "\n",
    "Now, we will represent this learning process in Python 3.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the modelling aproach\n",
    "\n",
    "Our action plan:\n",
    "\n",
    "1. Open Spyder üï∏Ô∏è\n",
    "2. Open **'ch4_florence_delta_solution.py'**\n",
    "3. Notice that \"blocks\" of code are separated by the ```#%%``` character\n",
    "4. Run these blocks of code by clicking inside this block and pressing ```shift + enter``` (```Ctrl + enter``` for Mac OS)\n",
    "5. Look at the output\n",
    "6. Sit back and listen to my explanation of each block!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using zeros to fill the array...\n",
      "\n",
      "Our original weight matrix, for now filled with zeros:\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import ch0_delta_learning as delta_learning\n",
    "import numpy              as np\n",
    "\n",
    "# alter print options for numpy: suppress scientific printing \n",
    "np.set_printoptions(suppress = True)\n",
    "\n",
    "image_florence   = [.99, .01, .99, .01, .99, .01]     # represents image\n",
    "song_stand_by_me = [.99, .99, .01, .01]               # represents song\n",
    "\n",
    "# define a weight matrix exclusively filled with zeros\n",
    "weight_matrix = delta_learning.initialise_weights(image_florence, \n",
    "                                                  song_stand_by_me, \n",
    "                                                  zeros      = True,\n",
    "                                                  predefined = False, \n",
    "                                                  verbose    = True)\n",
    "\n",
    "# show me what you got \n",
    "print('Our original weight matrix, for now filled with zeros:\\n', \n",
    "      weight_matrix)\n",
    "\n",
    "# make a copy of the original weight matrix\n",
    "original_weight_matrix = np.copy(weight_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The weight matrix\n",
    "\n",
    "Mind that the weight matrix looks different than the one we used in lesson 4.   \n",
    "To help you understand how our matrix looks like, we show this photo to make it clearer:\n",
    "\n",
    "![Weights](./weights.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activation levels at output for the original weight matrix:\n",
      " [0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# activation associated with the all zero weight matrix\n",
    "activation_original = delta_learning.internal_input(image_florence,\n",
    "                                                    weight_matrix)[0]\n",
    "print('\\nActivation levels at output for the original weight matrix:\\n', \n",
    "      activation_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our altered weight matrix after 1000 trials of delta learning:\n",
      " [[ 1.47000591  0.01417701  1.40351737  0.01356316  1.34274688  0.01301225]\n",
      " [ 1.47000591  0.01417701  1.40351737  0.01356316  1.34274688  0.01301225]\n",
      " [-1.47000591 -0.01417701 -1.40351737 -0.01356316 -1.34274688 -0.01301225]\n",
      " [-1.47000591 -0.01417701 -1.40351737 -0.01356316 -1.34274688 -0.01301225]]\n"
     ]
    }
   ],
   "source": [
    "loops = 1000\n",
    "alpha = 1.5\n",
    "    \n",
    "for loop_var in np.arange(1, loops + 1):\n",
    "    weights_after_learning = delta_learning.weight_change(alpha,\n",
    "                                                          image_florence,\n",
    "                                                          song_stand_by_me,\n",
    "                                                          weight_matrix)\n",
    "    weight_matrix = weights_after_learning\n",
    "\n",
    "\n",
    "print('\\nOur altered weight matrix after {} trials of delta learning:\\n'.format(loops), \n",
    "      weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activation levels at output after 1000 trials of delta learning:\n",
      " [0.985 0.985 0.015 0.015]\n"
     ]
    }
   ],
   "source": [
    "# activation associated with this altered weight matrix\n",
    "activation_after_learning = delta_learning.internal_input(image_florence,\n",
    "                                                          weight_matrix)[0]\n",
    "print('\\nActivation levels at output after {} trials of delta learning:\\n'.format(loops), \n",
    "      np.round(activation_after_learning, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Modelling the blocking effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic classical conditioning\n",
    "\n",
    "We consider the following situation\n",
    "\n",
    "![CS1 + US](./CS1_US.jpg)\n",
    "\n",
    "Here, the played sound is the **first conditioned stimulus (CS1)**.   \n",
    "We pair the sound with an electrical shock, which is referred to as the **unconditioned stimulus (US)**.   \n",
    "The reaction our subject has to the shock is often referred to as the **unconditioned response (UR)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic classical conditioning\n",
    "\n",
    "After pairing CS1 and US multiple times, the UR (confused screaming) will become the **conditioned response (CR)**.   \n",
    "Thus, the sound will elicit the screaming even though no shock was administered.\n",
    "\n",
    "![CR after conditioning](./CS1_conditioned.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The blocking effect\n",
    "\n",
    "Now we do extra conditioning, but we show CS1 together with a **second conditioned stimulus (CS2)** (e.g. a strong light).   \n",
    "After conditioning, CS1 + CS2 will also lead to confused screaming:\n",
    "\n",
    "![CS1 + CS2 + US](./CS1_CS2_US.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The blocking effect\n",
    "\n",
    "Interestingly, when we show CS2 alone, this will not lead to the CR [(Kamin, 1967)](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19680014821.pdf).\n",
    "\n",
    "![Reaction to CS2](./CS2_alone.jpg)\n",
    "\n",
    "It appears that a subject is not able to learn that the light also predicts the shock.   \n",
    "In other words: the learning of the CS2 - US association is _blocked_ because the CS1 - US assocation already exists..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modelling the blocking effect\n",
    "\n",
    "Now, we ask you to prove the blocking effect using a model.   \n",
    "You will have to do this yourself, relying on the code provided for exercise 1.   \n",
    "The questions asked below might help you out.\n",
    "\n",
    "* How many units does your model need?\n",
    "    * Input layer\n",
    "        * The model can encounter two different stimuli: **only sound** and **sound + light**\n",
    "        * Sound and light can be seen as two different units: if the unit is switched off, the stimulus is not available\n",
    "    * Output layer\n",
    "        * Only two outputs: aversion or no aversion --> this is doable with one unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modelling the blocking effect\n",
    "\n",
    "* Make a weight matrix to start with\n",
    "* Use delta learning to learn the outcome associated with **CS1**\n",
    "* Use delta learning to learn the outcome associated with **CS1 + CS2**\n",
    "   * Importantly, make sure that you use the weight matrix obtained from the previous step as a starting point\n",
    "* Does the end result prove blocking? Why / why not?\n",
    "   * How can you check investigate whether the blocking occured or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# 3. Delta learning: DIY with the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Why scikit-learn?\n",
    "\n",
    "Let's take a look at their own definition of what this package is about:\n",
    "\n",
    ">   sklearn is a Python module integrating classical machine\n",
    "    learning algorithms in the tightly-knit world of scientific Python\n",
    "    packages (numpy, scipy, matplotlib).   \n",
    "    It aims to provide simple and efficient solutions to learning problems\n",
    "    that are accessible to everybody and reusable in various contexts:\n",
    "    machine-learning as a versatile tool for science and engineering.\n",
    "    \n",
    "Thus, ```scikit-learn``` is about machine learning, and can be used for larger scale problems.   \n",
    "The drawback is that it solves problems in a 'black box' kind of way: the way how we get to the solution is not always clear.   \n",
    "We will use this module for this lesson and the next practical because it it allows us to do modelling, and it is quite famous in science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Iris dataset?\n",
    "\n",
    "In this exercise, we will use the iris dataset [(Fisher, 1936)](https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1469-1809.1936.tb02137.x).   \n",
    "More specifically, we will use this dataset to **predict the species** of the flower **based on the features** of the flower.\n",
    "   \n",
    "The dataset consists of 150 rows, where each row represents measurements of 150 different flowers.   \n",
    "Each flower is different, but they all belong to the same family: \"iris\".   \n",
    "There are 3 different species in the dataset, so we have 50 different flowers for each family.\n",
    "\n",
    "**The data available** üåπ  \n",
    "* Features of the flower\n",
    "    * Sepal width\n",
    "    * Sepal length\n",
    "    * Petal width\n",
    "    * Petal length\n",
    "* The name of the flower\n",
    "    * Iris setosa\n",
    "    * Iris virginica\n",
    "    * Iris vericolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## An example of the provided features\n",
    "\n",
    "![iris features](./iris.jpg)\n",
    "\n",
    "**Our question**   \n",
    "What iris _type (setosa, virginica or versicolor?)_ is this based on the provided measures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas  as     pd\n",
    "from   sklearn import datasets\n",
    "\n",
    "# import the Iris flower dataset\n",
    "iris        = datasets.load_iris()\n",
    "X           = iris.data\n",
    "y           = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# glue data together\n",
    "y           = np.reshape(y, \n",
    "                         (150, 1)) \n",
    "data_shown  = np.concatenate((X, y), \n",
    "                             axis = 1)\n",
    "iris_visual = pd.DataFrame(data_shown)\n",
    "\n",
    "# make column names\n",
    "colnames            = ['sep len', 'sep wid', \n",
    "                       'pet len', 'pet wid',\n",
    "                       'family']\n",
    "iris_visual.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 observations:\n",
      "    sep len  sep wid  pet len  pet wid  family\n",
      "0      5.1      3.5      1.4      0.2     0.0\n",
      "1      4.9      3.0      1.4      0.2     0.0\n",
      "2      4.7      3.2      1.3      0.2     0.0\n",
      "3      4.6      3.1      1.5      0.2     0.0\n",
      "4      5.0      3.6      1.4      0.2     0.0\n",
      "\n",
      "Last 5 observations:\n",
      "      sep len  sep wid  pet len  pet wid  family\n",
      "145      6.7      3.0      5.2      2.3     2.0\n",
      "146      6.3      2.5      5.0      1.9     2.0\n",
      "147      6.5      3.0      5.2      2.0     2.0\n",
      "148      6.2      3.4      5.4      2.3     2.0\n",
      "149      5.9      3.0      5.1      1.8     2.0\n"
     ]
    }
   ],
   "source": [
    "# show me the way (first 10 rows)\n",
    "print('First 5 observations:\\n', iris_visual[:5])\n",
    "print('\\nLast 5 observations:\\n',iris_visual[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ...?\n",
    "\n",
    "Our goal is to predict the family based on the provided features.   \n",
    "So, if we see the following:\n",
    "\n",
    "```python\n",
    "In [9]: X[10,:]\n",
    "Out[9]: array([5.4, 3.7, 1.5, 0.2])\n",
    "\n",
    "In [10]:y[10]\n",
    "Out[10]: 0\n",
    "```\n",
    "\n",
    "We know that flower 11 has a sepal length of 5.4 cm, sepal width of 3.7 cm ... .   \n",
    "We also know that flower 11 belongs to family 0 (i.e. setosa).\n",
    "\n",
    "Ideally, our model would be able to predict the family based on the features for every flower.   \n",
    "So, if we give the model the features for flower 62:\n",
    "\n",
    "```python\n",
    "In [16]: X[61,:]\n",
    "Out[16]: array([5.9, 3. , 4.2, 1.5])\n",
    "```\n",
    "\n",
    "we want to output of the model to be equal to 1 (i.e. versicolor), which is the observed family for flower 62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## The modelling perspective\n",
    "\n",
    "So, why the iris dataset?   \n",
    "When doing computational modelling, we might be interested in the processes behind object recognition.   \n",
    "In that case, we might train a model that is able to recognize flowers based on certain flower characteristics.   \n",
    "Additionally, we might even go further, and model how someone becomes an expert in recognizing flowers, what happens when we presents other objects to a flower expert ...   \n",
    "\n",
    "Now that the reason we use the iris dataset is (hopefully) clear, we move on to the actual exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Our action plan:\n",
    "\n",
    "1. Open **'ch4_iris_exercise.py'** \n",
    "2. Go through the script step by step and fill in the ```...``` spread throughout the code.\n",
    "    * Load the iris dataset, and select the flower features (named ```X```), and the labels ( named ```y```)\n",
    "    * Binarize the data: all observations that belong to class 1 should be relabeled so that they belong to class 2\n",
    "        * Think it through, why can we only handle two labels?\n",
    "    * Let the model learn 100 times\n",
    "        * Confused about the ```Perceptron``` object? No worries: ask us, or read through [the docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)\n",
    "    * Train the model by providing the correct arguments to the ```classification_algorithm.fit``` code\n",
    "    * Check the model accuracy by completing the ```classification_algorithm.predict``` code\n",
    "    * Print some statistics: how well did your model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import: general and scikit-learn specific\n",
    "import numpy                 as np\n",
    "\n",
    "from sklearn                 import datasets\n",
    "from sklearn.linear_model    import Perceptron\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import the Iris flower dataset\n",
    "iris        = datasets.load_iris()\n",
    "X           = iris.data\n",
    "y           = iris.target\n",
    "\n",
    "# binarize the data: we relabel 1 to 2\n",
    "   # thus, the flower is either class 0 or class 2\n",
    "y[np.where(y == 1)] = 2\n",
    "\n",
    "# split data in training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# define classifier (Perceptron object from scikit-learn)\n",
    "classification_algorithm = Perceptron(max_iter         = 100,\n",
    "                                      tol              = 1e-3,\n",
    "                                      verbose          = 0,\n",
    "                                      random_state     = 20,\n",
    "                                      n_iter_no_change = 5)\n",
    "\n",
    "# fit ('train') classifier to the training data\n",
    "classification_algorithm.fit(X_train, y_train)\n",
    "\n",
    "# predict y based on x for the test data\n",
    "y_pred = classification_algorithm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our classification was wrong for 0 out of the 38 cases.\n",
      "Accuracy percentage: 100.00\n"
     ]
    }
   ],
   "source": [
    "# select wrong predictions (absolute vals) and print them\n",
    "compared       = np.array(y_pred == y_test)\n",
    "absolute_wrong = (compared == False).sum()\n",
    "print(\"Our classification was wrong for {0} out of the {1} cases.\".format(absolute_wrong, \n",
    "                                                                          len(compared)))\n",
    "\n",
    "\n",
    "# print accuracy using dedicated function\n",
    "print('Accuracy percentage: {0:.2f}'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
