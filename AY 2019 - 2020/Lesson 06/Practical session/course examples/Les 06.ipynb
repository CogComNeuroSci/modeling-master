{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelling of Cognitive Processes\n",
    "---\n",
    "Lesson 06   \n",
    "29/10/2019   \n",
    "Pieter Huycke   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "## Theoretical\n",
    "- Delta learning: quick recap\n",
    "- Activation functions: quick recap\n",
    "\n",
    "## Practical\n",
    "1. Florence + the machine: a Delta learning tutorial\n",
    "2. Delta learning: DIY with the iris dataset\n",
    "3. Different patterns, equal learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Florence + the machine: a Delta learning tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The unknown artist\n",
    "\n",
    "Imagine you are listening to the radio, and suddenly a song comes up that you really like.   \n",
    "After the song, the radio host mentions the song 'Stand by me' by 'Florence + the machine'.   \n",
    "   \n",
    "You decide to search them online, and you find the following information..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence + the machine\n",
    "\n",
    "- English indie rock band\n",
    "- Formed in London in 2007\n",
    "- Lead singer: Florence Welch ‚¨áÔ∏è\n",
    "\n",
    "![Image of Florence](https://media.pitchfork.com/photos/5cbd2918ef5bbe6682d33c89/2:1/w_790/Florence-and-the-Machine.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the modelling aproach\n",
    "\n",
    "When you now hear _Stand by me_ again, you will be able to conjure up Florence's picture in your mind.   \n",
    "In MCP terms: you learned an association between two items.   \n",
    "Please note that encountering one item (the song) will result in the second item (the mental picture of Florence you saw online).\n",
    "\n",
    "We have already seen these dynamics in the cat-dog model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: comparison with the pet detector\n",
    "\n",
    "Note that the pet detector also worked with specific features.   \n",
    "\n",
    "![The pet detector](./fig01.jpg)\n",
    "\n",
    "Based on the aforementioned features being (un)available, the model will give a specific output.\n",
    "\n",
    "**Example**   \n",
    "```input = np.array([0, 1, 1])```?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: comparison with the pet detector\n",
    "\n",
    "**Model input**\n",
    "- Unit 1 is **inactive**: does not bite visitors\n",
    "- Unit 2 is **active**: has 4 legs\n",
    "- Unit 3 is **active**: has a picture on Facebook\n",
    "\n",
    "**Model output**   \n",
    "![cat image](https://images.pexels.com/photos/617278/pexels-photo-617278.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the modelling aproach\n",
    "\n",
    "Mind what happened:\n",
    "- First, the song was not associated with mental images\n",
    "- After the Google search, we could picture the singer of this song\n",
    "\n",
    "How?   \n",
    "**Learning**\n",
    "\n",
    "Now, we will represent this learning process in Python 3.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the modelling aproach\n",
    "\n",
    "Our action plan:\n",
    "\n",
    "1. Open Spyder üï∏Ô∏è\n",
    "2. Open **'ch4_florence_delta_solution.py'**\n",
    "3. Notice that \"blocks\" of code are separated by the ```#%%``` character\n",
    "4. Run these blocks of code by clicking inside this block and pressing ```shift + enter```\n",
    "5. Look at the output\n",
    "6. Sit back and listen to my explanation of each block!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using zeros to fill the array...\n",
      "\n",
      "Our original weight matrix, for now filled with zeros:\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import ch0_delta_learning as delta_learning\n",
    "import numpy              as np\n",
    "\n",
    "# alter print options for numpy: suppress scientific printing \n",
    "np.set_printoptions(suppress = True)\n",
    "\n",
    "image_florence   = [.99, .01, .99, .01, .99, .01]     # represent image using this pattern\n",
    "song_stand_by_me = [.99, .99, .01, .01]               # represent song using this pattern\n",
    "\n",
    "# define a weight matrix exclusively filled with zeros\n",
    "weight_matrix = delta_learning.initialise_weights(image_florence, \n",
    "                                                  song_stand_by_me, \n",
    "                                                  zeros      = True,\n",
    "                                                  predefined = False, \n",
    "                                                  verbose    = True)\n",
    "\n",
    "# show me what you got \n",
    "print('Our original weight matrix, for now filled with zeros:\\n', \n",
    "      weight_matrix)\n",
    "\n",
    "# make a copy of the original weight matrix\n",
    "original_weight_matrix = np.copy(weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activation levels at output for the original weight matrix:\n",
      " [0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# activation associated with the all zero weight matrix\n",
    "activation_original = delta_learning.internal_input(image_florence,\n",
    "                                                    weight_matrix)[0]\n",
    "print('\\nActivation levels at output for the original weight matrix:\\n', \n",
    "      activation_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our altered weight matrix after 1000 trials of delta learning:\n",
      " [[ 1.31   0.006  1.243  0.004  1.181  0.004]\n",
      " [ 1.31   0.006  1.243  0.004  1.181  0.004]\n",
      " [-1.31  -0.006 -1.243 -0.004 -1.181 -0.004]\n",
      " [-1.31  -0.006 -1.243 -0.004 -1.181 -0.004]]\n"
     ]
    }
   ],
   "source": [
    "loops = 1000\n",
    "alpha = 1.5\n",
    "    \n",
    "for loop_var in np.arange(1, loops + 1):\n",
    "    weights_after_learning = delta_learning.weight_change(alpha,\n",
    "                                                          image_florence,\n",
    "                                                          song_stand_by_me,\n",
    "                                                          weight_matrix)\n",
    "    weight_matrix = weights_after_learning\n",
    "\n",
    "\n",
    "print('\\nOur altered weight matrix after {} trials of delta learning:\\n'.format(loops), \n",
    "      weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activation levels at output after 1000 trials of delta learning:\n",
      " [0.976 0.976 0.024 0.024]\n"
     ]
    }
   ],
   "source": [
    "# activation associated with this altered weight matrix\n",
    "activation_after_learning = delta_learning.internal_input(image_florence,\n",
    "                                                          weight_matrix)[0]\n",
    "print('\\nActivation levels at output after {} trials of delta learning:\\n'.format(loops), \n",
    "      np.round(activation_after_learning, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Delta learning: DIY with the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iris dataset?\n",
    "\n",
    "In this exercise, we will use the iris dataset [(Fisher, 1936)](https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1469-1809.1936.tb02137.x).   \n",
    "More specifically, we will use this dataset to **predict the species** of the flower **based on the features** of the flower.\n",
    "   \n",
    "The dataset consists of 150 rows, where each row represents measurements of 150 different flowers.   \n",
    "Each flower is different, but they all belong to the same family: \"iris\".   \n",
    "There are 3 different species in the dataset, so we have 50 different flowers for each family.\n",
    "\n",
    "**The data available** üåπ  \n",
    "* Features of the flower\n",
    "    * Sepal width\n",
    "    * Sepal length\n",
    "    * Petal width\n",
    "    * Petal length\n",
    "* The name of the flower\n",
    "    * Iris setosa\n",
    "    * Iris virginica\n",
    "    * Iris vericolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An example of the provided features\n",
    "\n",
    "![iris features](./fig02.jpg)\n",
    "\n",
    "**Our question**   \n",
    "What iris _type (setosa, virginica or versicolor?)_ is this based on the provided measures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas  as     pd\n",
    "from   sklearn import datasets\n",
    "\n",
    "# import the Iris flower dataset\n",
    "iris        = datasets.load_iris()\n",
    "X           = iris.data\n",
    "y           = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# glue data together\n",
    "y           = np.reshape(y, \n",
    "                         (150, 1)) \n",
    "data_shown  = np.concatenate((X, y), \n",
    "                             axis = 1)\n",
    "iris_visual = pd.DataFrame(data_shown)\n",
    "\n",
    "# make column names\n",
    "colnames            = ['sep len', 'sep wid', \n",
    "                       'pet len', 'pet wid',\n",
    "                       'family']\n",
    "iris_visual.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 observations:\n",
      "    sep len  sep wid  pet len  pet wid  family\n",
      "0      5.1      3.5      1.4      0.2     0.0\n",
      "1      4.9      3.0      1.4      0.2     0.0\n",
      "2      4.7      3.2      1.3      0.2     0.0\n",
      "3      4.6      3.1      1.5      0.2     0.0\n",
      "4      5.0      3.6      1.4      0.2     0.0\n",
      "\n",
      "Last 5 observations:\n",
      "      sep len  sep wid  pet len  pet wid  family\n",
      "145      6.7      3.0      5.2      2.3     2.0\n",
      "146      6.3      2.5      5.0      1.9     2.0\n",
      "147      6.5      3.0      5.2      2.0     2.0\n",
      "148      6.2      3.4      5.4      2.3     2.0\n",
      "149      5.9      3.0      5.1      1.8     2.0\n"
     ]
    }
   ],
   "source": [
    "# show me the way (first 10 rows)\n",
    "print('First 5 observations:\\n', iris_visual[:5])\n",
    "print('\\nLast 5 observations:\\n',iris_visual[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ...?\n",
    "\n",
    "Our goal is to predict the family based on the provided features.   \n",
    "So, if we see the following:\n",
    "\n",
    "```python\n",
    "In [9]: X[10,:]\n",
    "Out[9]: array([5.4, 3.7, 1.5, 0.2])\n",
    "\n",
    "In [10]:y[10]\n",
    "Out[10]: 0\n",
    "```\n",
    "\n",
    "We know that flower 11 has a sepal length of 5.4 cm, sepal width of 3.7 cm ... .   \n",
    "We also know that flower 11 belongs to family 0 (i.e. setosa).\n",
    "\n",
    "Ideally, our model would be able to predict the family based on the features for every flower.   \n",
    "So, if we give the model the features for flower 62:\n",
    "\n",
    "```python\n",
    "In [16]: X[61,:]\n",
    "Out[16]: array([5.9, 3. , 4.2, 1.5])\n",
    "```\n",
    "\n",
    "we want to output of the model to be equal to 1 (i.e. versicolor), which is the observed family for flower 62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our action plan:\n",
    "\n",
    "1. Open **'ch4_iris_delta_exercise.py'** \n",
    "2. Use delta learning to let your model respond with the correct flower family based on the features\n",
    "3. Take a look at the Python module ```scikit-learn```, which allows us to implement a single layered model\n",
    "    * i.e. there are no layers between the input- and the output layer   \n",
    "3. Split the data in a training set and a testing set, use the training set to optimize the model, use the test set to check the performance of your model\n",
    "    * Google _split data train test scikit learn_, and see which Python functions might help you out üåê     \n",
    "4. Use the ```Perceptron``` function to make a single layered model, and train this model on the training set\n",
    "    * Stuck? Consider using ```help(Perceptron)``` to read the docs  \n",
    "5. Finally, check whether your trained model is able to predict the family of new observations (your test set serves as \"new observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import: general and scikit-learn specific\n",
    "import itertools\n",
    "import numpy                 as np\n",
    "import matplotlib.pyplot     as plt\n",
    "\n",
    "from sklearn                 import datasets\n",
    "from sklearn.linear_model    import Perceptron\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import the Iris flower dataset\n",
    "iris        = datasets.load_iris()\n",
    "X           = iris.data\n",
    "y           = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# split data in training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# train the standard scaler with a part of the data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "# apply scaler to all x\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std  = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define classifier (Perceptron object from scikit-learn)\n",
    "classification_algorithm = Perceptron(max_iter         = 1000,\n",
    "                                      tol              = 1e-3,\n",
    "                                      verbose          = 0,\n",
    "                                      random_state     = 20,\n",
    "                                      n_iter_no_change = 5)\n",
    "\n",
    "# fit ('train') classifier to the training data\n",
    "classification_algorithm.fit(X_train_std, \n",
    "                             y_train)\n",
    "\n",
    "# predict y based on x for the test data\n",
    "y_pred = classification_algorithm.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our classification was wrong for 2 out of the 38 cases.\n",
      "Accuracy percentage: 94.74\n"
     ]
    }
   ],
   "source": [
    "# select wrong predictions (absolute vals) and print them\n",
    "compared       = np.array(y_pred == y_test)\n",
    "absolute_wrong = (compared == False).sum()\n",
    "print(\"Our classification was wrong for {0} out of the {1} cases.\".format(absolute_wrong, \n",
    "                                                                          len(compared)))\n",
    "\n",
    "\n",
    "# print accuracy using dedicated function\n",
    "print('Accuracy percentage: {0:.2f}'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Different patterns, equal learning?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
