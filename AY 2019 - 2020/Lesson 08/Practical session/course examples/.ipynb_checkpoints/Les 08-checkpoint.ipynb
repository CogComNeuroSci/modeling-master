{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelling of Cognitive Processes\n",
    "## Delta learning \n",
    "---\n",
    "Lesson 08   \n",
    "12/11/2019   \n",
    "Pieter Huycke   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "## Theoretical\n",
    "- $scikit-learn?$\n",
    "\n",
    "## Practical\n",
    "1. Florence + the machine: novice\n",
    "2. The iris dataset: journeyman\n",
    "3. The iris dataset: adept\n",
    "4. The digits dataset: expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What?\n",
    "\n",
    "Let's take a look at the documentation the developers wrote for $scikit-learn$ ‚¨áÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine learning module for Python\n",
      "==================================\n",
      "\n",
      "sklearn is a Python module integrating classical machine\n",
      "learning algorithms in the tightly-knit world of scientific Python\n",
      "packages (numpy, scipy, matplotlib).\n",
      "\n",
      "It aims to provide simple and efficient solutions to learning problems\n",
      "that are accessible to everybody and reusable in various contexts:\n",
      "machine-learning as a versatile tool for science and engineering.\n",
      "\n",
      "See http://scikit-learn.org for complete documentation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why?\n",
    "\n",
    "<font color='green'>Advantages</font>\n",
    "* One can use $scikit-learn$ for modelling purposes, as we will be doing in a moment\n",
    "    * $scikit-learn$ was originally built for machine learning efforts though\n",
    "* It can be used for larger scale problems (e.g. process large amounts of input to the model)   \n",
    "* As it is a well-known package in (computational) science, knowledge of this package is a valuable skill to have\n",
    "\n",
    "<font color='red'>Disadvantages</font>\n",
    "* Sometimes $scikit-learn$ operates like a black box\n",
    "* The functions are predefined, so you might not find what you are looking for exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How?\n",
    "\n",
    "You can install $scikit-learn$ in your Anaconda environment using the following steps:\n",
    "1. Check if $scikit-learn$ is already installed by executing the following in your __Spyder console__\n",
    "```python\n",
    "import sklearn\n",
    "```\n",
    "2. If this throws no errors, you can stop reading\n",
    "3. If you are here, this means that you should close spyder, and open an __Anaconda prompt__\n",
    "4. In the prompt, type the following:\n",
    "```bash\n",
    "conda install -c anaconda scikit-learn\n",
    "```   \n",
    "5. Now type\n",
    "```bash\n",
    "spyder\n",
    "```\n",
    "6. In the new instance of Spyder, try _step 2_ and _step 3_ again\n",
    "\n",
    "<font color='red'>If this did not work out for you, raise your hand and ask for help</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A single slide on organizational matters\n",
    "\n",
    "1. At the end of exercises 1 and 2, some additional exercises are defined.   \n",
    "   These are meant as <font color='indigo'>homework assignments</font>, and will therefore not be considered during this practical session.\n",
    "2. In the next MCP test, we will ask you to program more than you did in test 2.   \n",
    "   You can prepare yourself adequately by completing the exercises in the practicals and the homeworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Florence + the machine: novice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the recap\n",
    "\n",
    "Quick recap of the previous practical session:\n",
    "- We had two patterns we wanted to associated with each other using Delta learning\n",
    "    - We had a pattern which represented an image of florence + the machine\n",
    "        - ```image_florence = [.99, .01, .99, .01, .99, .01]```\n",
    "    - Additionally, we had a pattern which represented an song of the same group\n",
    "        - ```song_stand_by_me = [.99, .99, .01, .01]```\n",
    "- To perform the Delta learning, we used custom-made code\n",
    "- <font color='green'>We succeeded to learn the association between the two patterns using Delta learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Making the old code work\n",
    "\n",
    "Now, we will adapt and extend the code from the previous practical and use $scikit-learn$ to perform learning.   \n",
    "Below, we define a list of adaptations that has to be completed to make sure the code from the previous practical works using $scikit-learn$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Adaptations to be done\n",
    "\n",
    "1. The output should be a 1D array, so we should work with integer values as output (i.e. ```group_1 = 0```).   \n",
    "   Mind that if you would check the dimensionality of a 1D array (```arr.shape```), your output would be: ```(x,)```.\n",
    "2. Note that $scikit-learn$ works best with NumPy arrays.   \n",
    "   So, the variables ```image_1``` and ```group_1``` should be converted to NumPy arrays.\n",
    "3. The input should be an $N \\times P$ array.   \n",
    "   Here, $N$ represents how many times the pattern is shown to the model.   \n",
    "   In contrast, $P$ is the length of the pattern.   \n",
    "    - So, if we showed the image 50 times, this would result in an array with dimensions $50 \\times 6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Extensions to be done\n",
    "\n",
    "1. Because ```scikit-learn``` works only when instances from several __different__ classes are offered, we will add another group image, and their associated label.\n",
    "    - Add a variabel refering to the image of your favorite group:   \n",
    "    ```image_2 = np.array([.01, .99, .01, .99, .01, .99])```\n",
    "2. Add a label associated with this new group: ```group_2 = 1```.\n",
    "3. We will use $N = 50$, meaning that we will show each image 50 times to the model.\n",
    "4. Link the associated label with each image, meaning that the model should react $0$ if the image of florence is shown, and $1$ if the image of the other group is presented.\n",
    "5. Comply with the needed array notation defined in _steps 2 & 3_ from the _Adaptations_ list.\n",
    "6. Find a way to shuffle the input array and the output array **together**.\n",
    "7. Use 75% of the input array to train your model, and test performance on the other 25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the modelling aproach\n",
    "\n",
    "Our action plan:\n",
    "\n",
    "1. Open **'ch4_florence_sklearn_exercise.py'**\n",
    "2. Fill in the blanks using the aforementioned explanation and the comments\n",
    "   - Mind that _how_ you fill in the blanks does not matter, **what matters is that it works...**\n",
    "3. Stuck? <font color='blue'>G</font><font color='red'>o</font><font color='yellow'>o</font><font color='blue'>g</font><font color='green'>l</font><font color='red'>e</font> is your friend üòâ\n",
    "4. Really stuck? Ask us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import: general and scikit-learn specific\n",
    "import numpy              as np\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics      import accuracy_score\n",
    "\n",
    "# define the patterns we need to associate\n",
    "image_florence   = np.array([.99, .01, .99, .01, .99, .01])\n",
    "song_florence    = 1\n",
    "\n",
    "image_bfmv       = np.array([.01, .99, .01, .99, .01, .99])\n",
    "song_bfmv        = 0\n",
    "\n",
    "# link patterns together in large array\n",
    "images           = np.vstack((image_florence, image_bfmv))\n",
    "songs            = np.vstack((song_florence, song_bfmv))\n",
    "\n",
    "n                = 50\n",
    "image_array      = np.repeat(images, \n",
    "                             n, \n",
    "                             axis = 0)\n",
    "song_array       = np.ravel(np.repeat(songs, \n",
    "                                      n, \n",
    "                                      axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle arrays together\n",
    "indx = np.arange(image_array.shape[0])\n",
    "np.random.shuffle(indx)\n",
    "\n",
    "image_array = image_array[indx]\n",
    "song_array  = song_array[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=2019, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data in the training proportion and the test proportion\n",
    "X_train, y_train, X_test, y_test = image_array[:75,:], song_array[:75], \\\n",
    "                                   image_array[75:,:], song_array[75:]\n",
    "\n",
    "# define classifier (Perceptron object from scikit-learn)\n",
    "classification_algorithm = Perceptron(max_iter         = 100,\n",
    "                                      tol              = 1e-3,\n",
    "                                      verbose          = 0,\n",
    "                                      random_state     = 2019,\n",
    "                                      n_iter_no_change = 5)\n",
    "\n",
    "# fit ('train') classifier to the training data\n",
    "classification_algorithm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage: 100.00\n"
     ]
    }
   ],
   "source": [
    "# predict y based on x for the test data\n",
    "y_pred = classification_algorithm.predict(X_test)\n",
    "\n",
    "# print accuracy using a built-in sklearn function\n",
    "print('Accuracy percentage: {0:.2f}'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <font color='indigo'>Homework assignment</font>\n",
    "\n",
    "Play around with the model, and check out how changing the parameters changes the model's performance\n",
    "\n",
    "* Add normally distributed noise\n",
    "* Let the model train more and less on the inputted patterns\n",
    "* Let the input patterns resemble each other more and less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. The iris dataset: journeyman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iris dataset?\n",
    "\n",
    "In this exercise, we will use the iris dataset [(Fisher, 1936)](https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1469-1809.1936.tb02137.x).   \n",
    "More specifically, we will use this dataset to **predict the species** of the flower **based on the features** of the flower.\n",
    "   \n",
    "The dataset consists of 150 rows, where each row represents measurements of 150 different flowers.   \n",
    "Each flower is different, but they all belong to the same family: \"iris\".   \n",
    "There are 3 different species in the dataset, so we have 50 different flowers for each family.\n",
    "\n",
    "**The data available** üåπ  \n",
    "* Features of the flower\n",
    "    * Sepal width\n",
    "    * Sepal length\n",
    "    * Petal width\n",
    "    * Petal length\n",
    "* The name of the flower\n",
    "    * Iris setosa    \n",
    "    * Iris versicolor\n",
    "    * Iris virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An example of the provided features\n",
    "\n",
    "![iris features](./iris.jpg)\n",
    "\n",
    "**Our question**   \n",
    "What iris _type (setosa, virginica or versicolor?)_ is this based on the provided measures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas  as     pd\n",
    "from   sklearn import datasets\n",
    "\n",
    "# import the Iris flower dataset\n",
    "iris        = datasets.load_iris()\n",
    "X           = iris.data\n",
    "y           = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# glue data together\n",
    "y           = np.reshape(y, \n",
    "                         (150, 1)) \n",
    "data_shown  = np.concatenate((X, y), \n",
    "                             axis = 1)\n",
    "iris_visual = pd.DataFrame(data_shown)\n",
    "\n",
    "# make column names\n",
    "colnames            = ['sep len', 'sep wid', \n",
    "                       'pet len', 'pet wid',\n",
    "                       'family']\n",
    "iris_visual.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 observations:\n",
      "    sep len  sep wid  pet len  pet wid  family\n",
      "0      5.1      3.5      1.4      0.2     0.0\n",
      "1      4.9      3.0      1.4      0.2     0.0\n",
      "2      4.7      3.2      1.3      0.2     0.0\n",
      "3      4.6      3.1      1.5      0.2     0.0\n",
      "4      5.0      3.6      1.4      0.2     0.0\n",
      "\n",
      "Last 5 observations:\n",
      "      sep len  sep wid  pet len  pet wid  family\n",
      "145      6.7      3.0      5.2      2.3     2.0\n",
      "146      6.3      2.5      5.0      1.9     2.0\n",
      "147      6.5      3.0      5.2      2.0     2.0\n",
      "148      6.2      3.4      5.4      2.3     2.0\n",
      "149      5.9      3.0      5.1      1.8     2.0\n"
     ]
    }
   ],
   "source": [
    "# show me the way (first 10 rows)\n",
    "print('First 5 observations:\\n', iris_visual[:5])\n",
    "print('\\nLast 5 observations:\\n',iris_visual[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ...?\n",
    "\n",
    "Our goal is to predict the family based on the provided features.   \n",
    "So, if we see the following:\n",
    "\n",
    "```python\n",
    "In [9]: X[10,:]\n",
    "Out[9]: array([5.4, 3.7, 1.5, 0.2])\n",
    "\n",
    "In [10]:y[10]\n",
    "Out[10]: 0\n",
    "```\n",
    "\n",
    "We know that flower 11 has a sepal length of 5.4 cm, sepal width of 3.7 cm ... .   \n",
    "We also know that flower 11 belongs to family 0 (i.e. setosa).\n",
    "\n",
    "Ideally, our model would be able to predict the family based on the features for every flower.   \n",
    "So, if we give the model the features for flower 62:\n",
    "\n",
    "```python\n",
    "In [16]: X[61,:]\n",
    "Out[16]: array([5.9, 3. , 4.2, 1.5])\n",
    "```\n",
    "\n",
    "we want to output of the model to be equal to 1 (i.e. versicolor), which is the observed family for flower 62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The modelling perspective\n",
    "\n",
    "So, why the iris dataset?   \n",
    "When doing computational modelling, we might be interested in the processes behind object recognition.   \n",
    "In that case, we might train a model that is able to recognize flowers based on certain flower characteristics.   \n",
    "Additionally, we might even go further, and model how someone becomes an expert in recognizing flowers, what happens when we presents other objects to a flower expert ...   \n",
    "\n",
    "Now that the reason we use the iris dataset is (hopefully) clear, we move on to the actual exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The iris dataset: journeyman\n",
    "\n",
    "<ins>Problem statement</ins>  \n",
    "\n",
    "Your task is to implement an algorithm in Python that is able to successfully separate flowers belonging to the __setosa__ and __virginica__ family, and to find out whether this task is linearly separable or not.   \n",
    "For now, we will use the entire Iris dataset, but we ask you to relabel the observations belonging to the 'versicolor' family to 'virginica'.   \n",
    "\n",
    "In line with the previous exercise, you should train your model on part of the data, and after training test the model on the rest of the data (extra: look for a built-in function in $scikit-learn$ that is able to shuffle and split the data in a training - and a testing part).   \n",
    "\n",
    "Print your classification accuracy at the end of your script, and infer based on your results whether your algorithm succeeded or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import: general and scikit-learn specific\n",
    "import numpy                 as np\n",
    "\n",
    "from sklearn                 import datasets\n",
    "from sklearn.linear_model    import Perceptron\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import the Iris flower dataset\n",
    "iris        = datasets.load_iris()\n",
    "X           = iris.data\n",
    "y           = iris.target\n",
    "\n",
    "# binarize the data: we relabel 1 to 2\n",
    "   # thus, the flower is either class 0 or class 2\n",
    "y[np.where(y == 1)] = 2\n",
    "\n",
    "# split data in training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# define classifier (Perceptron object from scikit-learn)\n",
    "classification_algorithm = Perceptron(max_iter         = 100,\n",
    "                                      tol              = 1e-3,\n",
    "                                      verbose          = 0,\n",
    "                                      random_state     = 2019,\n",
    "                                      n_iter_no_change = 5)\n",
    "\n",
    "# fit ('train') classifier to the training data\n",
    "classification_algorithm.fit(X_train, y_train)\n",
    "\n",
    "# predict y based on x for the test data\n",
    "y_pred = classification_algorithm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our classification was wrong for 38 out of the 38 cases.\n",
      "Accuracy percentage: 100.00\n"
     ]
    }
   ],
   "source": [
    "# select wrong predictions (absolute vals) and print them\n",
    "compared       = np.array(y_pred == y_test)\n",
    "absolute_wrong = (compared).sum()\n",
    "print(\"Our classification was wrong for {0} out of the {1} cases.\".format(absolute_wrong, \n",
    "                                                                          len(compared)))\n",
    "\n",
    "\n",
    "# print accuracy using dedicated function\n",
    "print('Accuracy percentage: {0:.2f}'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <font color='indigo'>Homework assignment</font>\n",
    "\n",
    "<ins>Problem statement</ins>  \n",
    "\n",
    "Check which **flower features** are linearly separable, and which ones are not.   \n",
    "Loop over each possible pair of features (sepal length + sepal width, sepal length + petal length ...) and determine whether this pair is linearly separable or not. \n",
    "\n",
    "Print your findings at the end of your script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The iris dataset: adept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The iris dataset: adept\n",
    "\n",
    "Note: no start script is provided as this script relies partly on the code from previous exercises.\n",
    "\n",
    "<ins>Problem statement</ins>  \n",
    "\n",
    "As we already saw in the theoretical part about delta learning, this learning algorithm only works when the provided inputs are linearly separable. For this assignment, we ask you to find out which flower families are linearly separable. Thus, can a delta learning algorithm separate setosa from virginica, or setosa from versicolor...?   \n",
    "\n",
    "Write a script that loops over each family comparison 50 times to account for variability in data shuffling and data splitting. Compute the minimal accuracy across simulations for each family comparison, and determine based on this which flower families are linearly separable, and which ones are not.\n",
    "\n",
    "The desired output should be of the form $50 \\times 3$, where $50$ represents the amount of simulations, and $3$ represents the amount of category comparisons that are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import: general and scikit-learn specific\n",
    "import itertools\n",
    "import numpy                 as np\n",
    "import pandas                as pd\n",
    "\n",
    "from sklearn                 import datasets\n",
    "from sklearn.linear_model    import Perceptron\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import the iris flower dataset\n",
    "iris = datasets.load_iris()\n",
    "X    = iris.data\n",
    "y    = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# define where to store the simulation results\n",
    "arr = np.zeros((50, 3))\n",
    "\n",
    "# find all permutations\n",
    "permutations = list(itertools.combinations('012', 2))\n",
    "\n",
    "# 50 simulations for each comparison\n",
    "for i in range(50):\n",
    "    for perm in permutations:\n",
    "        \n",
    "        # apply boolean mask to get the values we need from the array\n",
    "        first_class, second_class = int(perm[0]), int(perm[1])\n",
    "        mask    = np.where((y == first_class) | (y == second_class))\n",
    "        X_selec = X[mask]\n",
    "        y_selec = y[mask]\n",
    "    \n",
    "        # split data in training and testing set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_selec, \n",
    "                                                            y_selec)\n",
    "        \n",
    "        # classifier\n",
    "        classification_algorithm = Perceptron(max_iter         = 100,\n",
    "                                              tol              = 1e-3,\n",
    "                                              verbose          = 0,\n",
    "                                              n_iter_no_change = 5)\n",
    "        \n",
    "        # fit ('train') classifier to the training data\n",
    "        classification_algorithm.fit(X_train, y_train)\n",
    "        \n",
    "        # predict y based on x for the test data\n",
    "        y_pred = classification_algorithm.predict(X_test)\n",
    "        \n",
    "        # link the names of the families to the int label\n",
    "        name_dict = {0: 'setosa',\n",
    "                     1: 'versicolor',\n",
    "                     2: 'virginica'}\n",
    "        \n",
    "        # store the accuracy in the pandas DataFrame\n",
    "        arr[i, permutations.index(perm)] = accuracy_score(y_test, y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininum accuracy of Setosa vs Versicolor: 96.0 %\n",
      "Mininum accuracy of Setosa vs Virginica: 100.0 %\n",
      "Mininum accuracy of Versicolor vs Virginica: 36.0 %\n"
     ]
    }
   ],
   "source": [
    "# results of the simulation    \n",
    "simulation_results         = pd.DataFrame(arr)\n",
    "colnames                   = ['Set - Vers', 'Set - Virg', 'Vers - Virg']\n",
    "simulation_results.columns = colnames\n",
    "\n",
    "print('Mininum accuracy of Setosa vs Versicolor: {} %'.format(np.min(simulation_results['Set - Vers'])))\n",
    "print('Mininum accuracy of Setosa vs Virginica: {} %'.format(np.min(simulation_results['Set - Virg'])))\n",
    "print('Mininum accuracy of Versicolor vs Virginica: {} %'.format(np.min(simulation_results['Vers - Virg'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The digits dataset: expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The digits dataset\n",
    "\n",
    "This dataset is made up of 1797 $8 \\times 8$ images.   \n",
    "Each image, like the one shown below (representing number 1), is of a hand-written digit.   \n",
    "The dataset is included in ```sklearn.datasets```.   \n",
    "Additional information can be found on [this webpage](https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits).\n",
    "\n",
    "![Digit example](./digit_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The digits dataset\n",
    "\n",
    "We can see that this array $1797 \\times 8 \\times 8$ represents 1797 images, each image being a square of $8 \\times 8$ representing pixel values.   \n",
    "Here, larger values represent darker pixels, so:\n",
    "- ```image[0, 0, 0] == 0.0```  ‚û°Ô∏è this pixel will be plotted in white\n",
    "- ```image[0, 4, 2] == 8.0```  ‚û°Ô∏è this pixel will be plotted in gray\n",
    "- ```image[0, 1, 3] == 15.0``` ‚û°Ô∏è this pixel will be plotted in black\n",
    "\n",
    "We illustrate this point immediately below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "\n",
    "from   sklearn           import datasets, svm, metrics\n",
    "\n",
    "# load data\n",
    "digits = datasets.load_digits()\n",
    "X      = digits.images\n",
    "y      = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the input data:  (1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing dims\n",
    "print(\"Dimensions of the input data: \", X.shape)\n",
    "\n",
    "# concatenate elements row wise + select first four\n",
    "images_and_labels = list(zip(X, y))\n",
    "first_four        = images_and_labels[:4]\n",
    "\n",
    "# plot the first four elements in the dataset\n",
    "for index, (image, label) in enumerate(first_four):\n",
    "    plt.subplot(1, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, \n",
    "               cmap          = plt.cm.gray_r, \n",
    "               interpolation = 'nearest')\n",
    "    plt.title('Number: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The digits dataset: expert\n",
    "\n",
    "Note: no start script is provided as this is an expert exercise, good luck! ü§ñ\n",
    "\n",
    "<ins>Problem statement</ins>  \n",
    "\n",
    "Image processing is a valuable skill to have, so in this exercise, we ask you to load in the digits dataset available in the standard version of $scikit-learn$. Your goal is straightforward: process the images, feed them to a delta learning algorithm, and check whether you are able to let the model distinguish one number (e.g. $7$) from all the other numbers.   \n",
    "\n",
    "Think about the logical steps that you should take to succeed in this exercise.   \n",
    "What does your delta learning model need? How should the input to the model look like? \n",
    "\n",
    "Is classification of images a linearly separable problem or not?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
