{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelling of Cognitive Processes\n",
    "## Delta learning \n",
    "---\n",
    "Lesson 08   \n",
    "12/11/2019   \n",
    "Pieter Huycke   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "## Theoretical\n",
    "- $scikit-learn?$\n",
    "\n",
    "## Practical\n",
    "1. Florence + the machine, but now in $scikit-learn$\n",
    "2. Delta learning: DIY with the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What?\n",
    "\n",
    "Let's take a look at their own definition of what this package is about ‚¨áÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine learning module for Python\n",
      "==================================\n",
      "\n",
      "sklearn is a Python module integrating classical machine\n",
      "learning algorithms in the tightly-knit world of scientific Python\n",
      "packages (numpy, scipy, matplotlib).\n",
      "\n",
      "It aims to provide simple and efficient solutions to learning problems\n",
      "that are accessible to everybody and reusable in various contexts:\n",
      "machine-learning as a versatile tool for science and engineering.\n",
      "\n",
      "See http://scikit-learn.org for complete documentation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why?\n",
    "\n",
    "<font color='green'>Advantages</font>\n",
    "* One can use $scikit-learn$ for modelling purposes, as we will be doing in a moment\n",
    "    * $scikit-learn$ was originally built for machine learning efforts though\n",
    "* It can be used for larger scale problems (e.g. process large amounts of input to the model)   \n",
    "* As it is a well-known package in (computational) science, knowledge of this package is a valuable skill to have\n",
    "\n",
    "<font color='red'>Disadvantages</font>\n",
    "* Sometimes $scikit-learn$ operates like a black box\n",
    "* The functions are predefined, so you might not find what you are looking for exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How?\n",
    "\n",
    "You can install $scikit-learn$ in your Anaconda environment using the following steps:\n",
    "1. Check if $scikit-learn$ is already installed by executing the following in your __Spyder console__\n",
    "```python\n",
    "import sklearn\n",
    "```\n",
    "2. If this throws no errors, you can stop reading\n",
    "3. If you are here, this means that you should close spyder, and open an __Anaconda prompt__\n",
    "4. In the prompt, type the following:\n",
    "```bash\n",
    "conda install -c anaconda scikit-learn\n",
    "```   \n",
    "5. Now type\n",
    "```bash\n",
    "spyder\n",
    "```\n",
    "6. In the new instance of Spyder, try _step 2_ and _step 3_ again\n",
    "\n",
    "<font color='red'>If this did not work out for you, raise your hand and ask for help</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Florence + the machine, but now in $scikit-learn$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the recap\n",
    "\n",
    "Quick recap of the previous practical session:\n",
    "- We had two patterns we wanted to associated with each other using Delta learning\n",
    "    - We had a pattern which represented an image of florence + the machine\n",
    "        - ```image_florence = [.99, .01, .99, .01, .99, .01]```\n",
    "    - Additionally, we had a pattern which represented an song of the same group\n",
    "        - ```song_stand_by_me = [.99, .99, .01, .01]```\n",
    "- To perform the Delta learning, we used custom-made code\n",
    "- <font color='green'>We succeeded to learn the association between the two patterns using Delta learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Making the old code work\n",
    "\n",
    "Now, we will adapt and extend the code from the previous practical and use $scikit-learn$ to perform learning.   \n",
    "Below, we define a list of adaptations that have to be done to make sure the code from the previous practical works for $scikit-learn$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Adaptations to be done\n",
    "\n",
    "1. The output should be a 1D array, meaning that we cannot work with patterns like ```song_florence``` anymore.   \n",
    "   Instead, we should work with integer values (i.e. ```song_florence = 1```).   \n",
    "   To convert an array to a 1D array, use the NumPy function ```np.ravel()```\n",
    "2. Note that $scikit-learn$ works best with NumPy arrays.   \n",
    "   So, the variables ```image_florence``` and ```song_florence``` should be converted to NumPy arrays.\n",
    "3. The input should be an $N \\times P$ array.   \n",
    "   Here, $N$ represents how many times the pattern is shown to the model.   \n",
    "   In contrast, $P$ is the length of the pattern.   \n",
    "    - So, if we showed the image 50 times, this would result in an array with dimensions 50 x 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Extensions to be done\n",
    "\n",
    "1. Because ```scikit-learn``` works only when instances from several __different__ classes are offered, we will add another group image, and their associated label\n",
    "    - Add a variabel refering to the image of your favorite group:   \n",
    "    ```groupname = np.array([.01, .99, .01, .99, .01, .99])```\n",
    "2. Add a label associated with this new group: ```song_... = 0```\n",
    "3. We will use $N = 50$, meaning that we will show each image 50 times to the model\n",
    "4. Link the associated label with each image, meaning that the model should react $0$ if the image of florence is shown, and $1$ if the image of the other group is presented\n",
    "5. Comply with the needed array notation defined in _steps 2 & 3_ from the _Adaptations_ list\n",
    "6. Find a way to shuffle the input array and the output array **together**\n",
    "7. Use 75% of the input array to train your model, and test performance on the other 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Florence: the modelling aproach\n",
    "\n",
    "Our action plan:\n",
    "\n",
    "1. Open **'ch4_florence_sklearn_exercise.py'**\n",
    "2. Fill in the blanks using the aforementioned explanation and the comments\n",
    "   - Mind that _how_ you fill in the blanks does not matter, **what matters is that it works**\n",
    "3. Stuck? <font color='blue'>G</font><font color='red'>o</font><font color='yellow'>o</font><font color='blue'>g</font><font color='green'>l</font><font color='red'>e</font> is your friend üòâ\n",
    "4. Really stuck? Ask us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import: general and scikit-learn specific\n",
    "import numpy              as np\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics      import accuracy_score\n",
    "\n",
    "# define the patterns we need to associate\n",
    "image_florence   = np.array([.99, .01, .99, .01, .99, .01])\n",
    "song_florence    = 1\n",
    "\n",
    "image_bfmv       = np.array([.01, .99, .01, .99, .01, .99])\n",
    "song_bfmv        = 0\n",
    "\n",
    "# link patterns together in large array\n",
    "images           = np.vstack((image_florence, image_bfmv))\n",
    "songs            = np.vstack((song_florence, song_bfmv))\n",
    "\n",
    "n                = 50\n",
    "image_array      = np.repeat(images, \n",
    "                             n, \n",
    "                             axis = 0)\n",
    "song_array       = np.ravel(np.repeat(songs, \n",
    "                                      n, \n",
    "                                      axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle arrays together\n",
    "indx = np.arange(image_array.shape[0])\n",
    "np.random.shuffle(indx)\n",
    "\n",
    "image_array = image_array[indx]\n",
    "song_array  = song_array[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=2019, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data in the training proportion and the test proportion\n",
    "X_train, y_train, X_test, y_test = image_array[:75,:], song_array[:75], \\\n",
    "                                   image_array[75:,:], song_array[75:]\n",
    "\n",
    "# define classifier (Perceptron object from scikit-learn)\n",
    "classification_algorithm = Perceptron(max_iter         = 100,\n",
    "                                      tol              = 1e-3,\n",
    "                                      verbose          = 0,\n",
    "                                      random_state     = 2019,\n",
    "                                      n_iter_no_change = 5)\n",
    "\n",
    "# fit ('train') classifier to the training data\n",
    "classification_algorithm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage: 100.00\n"
     ]
    }
   ],
   "source": [
    "# predict y based on x for the test data\n",
    "y_pred = classification_algorithm.predict(X_test)\n",
    "\n",
    "# print accuracy using a built-in sklearn function\n",
    "print('Accuracy percentage: {0:.2f}'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Delta learning: DIY with the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iris dataset?\n",
    "\n",
    "In this exercise, we will use the iris dataset [(Fisher, 1936)](https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1469-1809.1936.tb02137.x).   \n",
    "More specifically, we will use this dataset to **predict the species** of the flower **based on the features** of the flower.\n",
    "   \n",
    "The dataset consists of 150 rows, where each row represents measurements of 150 different flowers.   \n",
    "Each flower is different, but they all belong to the same family: \"iris\".   \n",
    "There are 3 different species in the dataset, so we have 50 different flowers for each family.\n",
    "\n",
    "**The data available** üåπ  \n",
    "* Features of the flower\n",
    "    * Sepal width\n",
    "    * Sepal length\n",
    "    * Petal width\n",
    "    * Petal length\n",
    "* The name of the flower\n",
    "    * Iris setosa\n",
    "    * Iris virginica\n",
    "    * Iris vericolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An example of the provided features\n",
    "\n",
    "![iris features](./iris.jpg)\n",
    "\n",
    "**Our question**   \n",
    "What iris _type (setosa, virginica or versicolor?)_ is this based on the provided measures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas  as     pd\n",
    "from   sklearn import datasets\n",
    "\n",
    "# import the Iris flower dataset\n",
    "iris        = datasets.load_iris()\n",
    "X           = iris.data\n",
    "y           = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# glue data together\n",
    "y           = np.reshape(y, \n",
    "                         (150, 1)) \n",
    "data_shown  = np.concatenate((X, y), \n",
    "                             axis = 1)\n",
    "iris_visual = pd.DataFrame(data_shown)\n",
    "\n",
    "# make column names\n",
    "colnames            = ['sep len', 'sep wid', \n",
    "                       'pet len', 'pet wid',\n",
    "                       'family']\n",
    "iris_visual.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 observations:\n",
      "    sep len  sep wid  pet len  pet wid  family\n",
      "0      5.1      3.5      1.4      0.2     0.0\n",
      "1      4.9      3.0      1.4      0.2     0.0\n",
      "2      4.7      3.2      1.3      0.2     0.0\n",
      "3      4.6      3.1      1.5      0.2     0.0\n",
      "4      5.0      3.6      1.4      0.2     0.0\n",
      "\n",
      "Last 5 observations:\n",
      "      sep len  sep wid  pet len  pet wid  family\n",
      "145      6.7      3.0      5.2      2.3     2.0\n",
      "146      6.3      2.5      5.0      1.9     2.0\n",
      "147      6.5      3.0      5.2      2.0     2.0\n",
      "148      6.2      3.4      5.4      2.3     2.0\n",
      "149      5.9      3.0      5.1      1.8     2.0\n"
     ]
    }
   ],
   "source": [
    "# show me the way (first 10 rows)\n",
    "print('First 5 observations:\\n', iris_visual[:5])\n",
    "print('\\nLast 5 observations:\\n',iris_visual[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ...?\n",
    "\n",
    "Our goal is to predict the family based on the provided features.   \n",
    "So, if we see the following:\n",
    "\n",
    "```python\n",
    "In [9]: X[10,:]\n",
    "Out[9]: array([5.4, 3.7, 1.5, 0.2])\n",
    "\n",
    "In [10]:y[10]\n",
    "Out[10]: 0\n",
    "```\n",
    "\n",
    "We know that flower 11 has a sepal length of 5.4 cm, sepal width of 3.7 cm ... .   \n",
    "We also know that flower 11 belongs to family 0 (i.e. setosa).\n",
    "\n",
    "Ideally, our model would be able to predict the family based on the features for every flower.   \n",
    "So, if we give the model the features for flower 62:\n",
    "\n",
    "```python\n",
    "In [16]: X[61,:]\n",
    "Out[16]: array([5.9, 3. , 4.2, 1.5])\n",
    "```\n",
    "\n",
    "we want to output of the model to be equal to 1 (i.e. versicolor), which is the observed family for flower 62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The modelling perspective\n",
    "\n",
    "So, why the iris dataset?   \n",
    "When doing computational modelling, we might be interested in the processes behind object recognition.   \n",
    "In that case, we might train a model that is able to recognize flowers based on certain flower characteristics.   \n",
    "Additionally, we might even go further, and model how someone becomes an expert in recognizing flowers, what happens when we presents other objects to a flower expert ...   \n",
    "\n",
    "Now that the reason we use the iris dataset is (hopefully) clear, we move on to the actual exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our action plan:\n",
    "\n",
    "1. Open **'ch4_iris_exercise.py'** \n",
    "2. Go through the script step by step and fill in the ```...``` spread throughout the code.\n",
    "    * Load the iris dataset, and select the flower features (named ```X```), and the labels ( named ```y```)\n",
    "    * Binarize the data: all observations that belong to class 1 should be relabeled so that they belong to class 2\n",
    "        * Think it through, why can we only handle two labels?\n",
    "    * Let the model learn 100 times\n",
    "        * Confused about the ```Perceptron``` object? No worries: ask us, or read through [the docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)\n",
    "    * Train the model by providing the correct arguments to the ```classification_algorithm.fit``` code\n",
    "    * Check the model accuracy by completing the ```classification_algorithm.predict``` code\n",
    "    * Print some statistics: how well did your model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import: general and scikit-learn specific\n",
    "import numpy                 as np\n",
    "\n",
    "from sklearn                 import datasets\n",
    "from sklearn.linear_model    import Perceptron\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import the Iris flower dataset\n",
    "iris        = datasets.load_iris()\n",
    "X           = iris.data\n",
    "y           = iris.target\n",
    "\n",
    "# binarize the data: we relabel 1 to 2\n",
    "   # thus, the flower is either class 0 or class 2\n",
    "y[np.where(y == 1)] = 2\n",
    "\n",
    "# split data in training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define classifier (Perceptron object from scikit-learn)\n",
    "classification_algorithm = Perceptron(max_iter         = 100,\n",
    "                                      tol              = 1e-3,\n",
    "                                      verbose          = 0,\n",
    "                                      random_state     = 20,\n",
    "                                      n_iter_no_change = 5)\n",
    "\n",
    "# fit ('train') classifier to the training data\n",
    "classification_algorithm.fit(X_train, y_train)\n",
    "\n",
    "# predict y based on x for the test data\n",
    "y_pred = classification_algorithm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our classification was wrong for 0 out of the 38 cases.\n",
      "Accuracy percentage: 100.00\n"
     ]
    }
   ],
   "source": [
    "# select wrong predictions (absolute vals) and print them\n",
    "compared       = np.array(y_pred == y_test)\n",
    "absolute_wrong = (compared == False).sum()\n",
    "print(\"Our classification was wrong for {0} out of the {1} cases.\".format(absolute_wrong, \n",
    "                                                                          len(compared)))\n",
    "\n",
    "\n",
    "# print accuracy using dedicated function\n",
    "print('Accuracy percentage: {0:.2f}'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
